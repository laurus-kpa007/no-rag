"""
PageIndex Ultra-Precision Ensemble Answer Generation Module

ì´ ëª¨ë“ˆì€ ì—¬ëŸ¬ ì ‘ê·¼ë²•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ì´ë¥¼ ì¢…í•©í•˜ëŠ” ì•™ìƒë¸” ë°©ì‹ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ì•™ìƒë¸” ì „ëµ:
1. Conservative (ë³´ìˆ˜ì ): ëª…í™•íˆ ì¦ëª…ëœ ì •ë³´ë§Œ í¬í•¨
2. Balanced (ê· í˜•): ì§ì ‘ ì¦ê±° + ì¶”ë¡  ê°€ëŠ¥í•œ ì •ë³´ í¬í•¨
3. Comprehensive (í¬ê´„ì ): ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ëª¨ë“  ì •ë³´ í¬í•¨

â†’ 3ê°€ì§€ ë‹µë³€ì„ LLMì´ ë¹„êµ ë¶„ì„í•˜ì—¬ ìµœì¢… ì¢…í•© ë‹µë³€ ìƒì„±
"""

from typing import List, Tuple, Dict
from dataclasses import dataclass
from enum import Enum


class AnswerStrategy(Enum):
    """ë‹µë³€ ìƒì„± ì „ëµ"""
    CONSERVATIVE = "conservative"      # ë³´ìˆ˜ì : ëª…í™•í•œ ì¦ê±°ë§Œ
    BALANCED = "balanced"              # ê· í˜•: ì§ì ‘ ì¦ê±° + ì¶”ë¡ 
    COMPREHENSIVE = "comprehensive"    # í¬ê´„ì : ëª¨ë“  ê´€ë ¨ ì •ë³´


@dataclass
class EnsembleAnswer:
    """ì•™ìƒë¸” ë‹µë³€"""
    strategy: AnswerStrategy
    answer: str
    confidence: float  # 0-1
    sources: List[str]  # ì‚¬ìš©ëœ ì„¹ì…˜ ì œëª©


@dataclass
class SynthesizedAnswer:
    """ì¢…í•©ëœ ìµœì¢… ë‹µë³€"""
    answer: str
    confidence: float  # 0-100
    strategy_breakdown: Dict[str, str]  # {ì „ëµëª…: ë‹µë³€}
    synthesis_rationale: str  # ì¢…í•© ê·¼ê±°
    recommended_sections: List[str]  # ì°¸ì¡° ì„¹ì…˜


class EnsembleAnswerGenerator:
    """ì•™ìƒë¸” ë‹µë³€ ìƒì„±ê¸°"""

    def __init__(self, client, model: str = 'gemma3:12b'):
        """
        Args:
            client: Ollama í´ë¼ì´ì–¸íŠ¸
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
        """
        self.client = client
        self.model = model

    def generate_ensemble_answers(self,
                                  query: str,
                                  sections: List[Tuple[str, str]],
                                  section_scores: List[Dict],
                                  evidence_verified: Dict[str, bool] = None) -> List[EnsembleAnswer]:
        """
        3ê°€ì§€ ì „ëµìœ¼ë¡œ ë‹µë³€ ìƒì„±

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            sections: [(ì œëª©, ë‚´ìš©), ...] ê²€ìƒ‰ëœ ì„¹ì…˜ë“¤
            section_scores: ì„¹ì…˜ë³„ ì ìˆ˜ ì •ë³´
            evidence_verified: {ì„¹ì…˜ëª…: ê²€ì¦ì—¬ë¶€} (ì˜µì…˜)

        Returns:
            List[EnsembleAnswer]: 3ê°€ì§€ ì „ëµì˜ ë‹µë³€ë“¤
        """
        answers = []

        # 1. Conservative (ë³´ìˆ˜ì ) ë‹µë³€
        conservative_answer = self._generate_conservative(
            query, sections, section_scores, evidence_verified)
        answers.append(conservative_answer)

        # 2. Balanced (ê· í˜•) ë‹µë³€
        balanced_answer = self._generate_balanced(
            query, sections, section_scores)
        answers.append(balanced_answer)

        # 3. Comprehensive (í¬ê´„ì ) ë‹µë³€
        comprehensive_answer = self._generate_comprehensive(
            query, sections, section_scores)
        answers.append(comprehensive_answer)

        return answers

    def _generate_conservative(self,
                               query: str,
                               sections: List[Tuple[str, str]],
                               section_scores: List[Dict],
                               evidence_verified: Dict[str, bool] = None) -> EnsembleAnswer:
        """
        ë³´ìˆ˜ì  ë‹µë³€ ìƒì„±: ëª…í™•íˆ ê²€ì¦ëœ ì •ë³´ë§Œ ì‚¬ìš©

        ì „ëµ:
        - ì ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 30% ì„¹ì…˜ë§Œ ì‚¬ìš©
        - ì¦ê±°ê°€ ê²€ì¦ëœ ì •ë³´ë§Œ í¬í•¨
        - "í™•ì‹¤í•˜ì§€ ì•ŠìŒ" ëª…ì‹œ
        """
        # ìƒìœ„ 30% ì„¹ì…˜ ì„ íƒ
        sorted_sections = sorted(
            zip(sections, section_scores),
            key=lambda x: x[1].get('total_score', 0),
            reverse=True
        )
        top_count = max(1, int(len(sorted_sections) * 0.3))
        top_sections = [s for s, _ in sorted_sections[:top_count]]

        # ê²€ì¦ëœ ì„¹ì…˜ë§Œ í•„í„°ë§ (ìˆìœ¼ë©´)
        if evidence_verified:
            top_sections = [(t, c) for t, c in top_sections
                            if evidence_verified.get(t, False)]

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì§§ê²Œ)
        context = "\n\n".join([
            f"[{title}]\n{content[:400]}..."
            for title, content in top_sections
        ])

        prompt = f"""ì§ˆë¬¸: {query}

ì»¨í…ìŠ¤íŠ¸ (ê²€ì¦ëœ ì •ë³´ë§Œ):
{context}

**ë³´ìˆ˜ì  ë‹µë³€ ê·œì¹™**:
1. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ëª…í™•íˆ í™•ì¸ëœ ì •ë³´ë§Œ ì‚¬ìš©
2. ì¶”ë¡ ì´ë‚˜ ê°€ì •ì„ í”¼í•¨
3. ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ "í™•ì¸ë˜ì§€ ì•ŠìŒ" ëª…ì‹œ
4. ê°„ê²°í•˜ê²Œ ë‹µë³€ (3-5ë¬¸ì¥)

ë‹µë³€:"""

        response = self.client.chat(model=self.model, messages=[
            {'role': 'user', 'content': prompt}
        ])

        answer_text = response['message']['content']
        used_sections = [title for title, _ in top_sections]

        return EnsembleAnswer(
            strategy=AnswerStrategy.CONSERVATIVE,
            answer=answer_text,
            confidence=0.9,  # ë³´ìˆ˜ì ì´ë¯€ë¡œ ë†’ì€ ì‹ ë¢°ë„
            sources=used_sections
        )

    def _generate_balanced(self,
                           query: str,
                           sections: List[Tuple[str, str]],
                           section_scores: List[Dict]) -> EnsembleAnswer:
        """
        ê· í˜• ë‹µë³€ ìƒì„±: ì§ì ‘ ì¦ê±° + í•©ë¦¬ì  ì¶”ë¡ 

        ì „ëµ:
        - ìƒìœ„ 50% ì„¹ì…˜ ì‚¬ìš©
        - ì§ì ‘ ì¦ê±°ë¥¼ ìš°ì„ í•˜ë˜, ë…¼ë¦¬ì  ì¶”ë¡ ë„ í¬í•¨
        - ì¶”ë¡  ë¶€ë¶„ì€ ëª…ì‹œ
        """
        # ìƒìœ„ 50% ì„¹ì…˜ ì„ íƒ
        sorted_sections = sorted(
            zip(sections, section_scores),
            key=lambda x: x[1].get('total_score', 0),
            reverse=True
        )
        top_count = max(2, int(len(sorted_sections) * 0.5))
        top_sections = [s for s, _ in sorted_sections[:top_count]]

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì¤‘ê°„ ê¸¸ì´)
        context = "\n\n".join([
            f"[{title}]\n{content[:600]}..."
            for title, content in top_sections
        ])

        prompt = f"""ì§ˆë¬¸: {query}

ì»¨í…ìŠ¤íŠ¸:
{context}

**ê· í˜• ë‹µë³€ ê·œì¹™**:
1. ì»¨í…ìŠ¤íŠ¸ì˜ ì§ì ‘ ì¦ê±°ë¥¼ ìš°ì„  ì‚¬ìš©
2. ë…¼ë¦¬ì  ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš°, "ì¶”ë¡ : ..."ìœ¼ë¡œ ëª…ì‹œ
3. ì§ì ‘ ì¦ê±°ì™€ ì¶”ë¡ ì„ êµ¬ë¶„
4. ì ì ˆí•œ ê¸¸ì´ë¡œ ë‹µë³€ (5-8ë¬¸ì¥)

ë‹µë³€:"""

        response = self.client.chat(model=self.model, messages=[
            {'role': 'user', 'content': prompt}
        ])

        answer_text = response['message']['content']
        used_sections = [title for title, _ in top_sections]

        return EnsembleAnswer(
            strategy=AnswerStrategy.BALANCED,
            answer=answer_text,
            confidence=0.75,  # ì¤‘ê°„ ì‹ ë¢°ë„
            sources=used_sections
        )

    def _generate_comprehensive(self,
                                query: str,
                                sections: List[Tuple[str, str]],
                                section_scores: List[Dict]) -> EnsembleAnswer:
        """
        í¬ê´„ì  ë‹µë³€ ìƒì„±: ê´€ë ¨ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ í¬í•¨

        ì „ëµ:
        - ëª¨ë“  ì„¹ì…˜ ì‚¬ìš© (ë˜ëŠ” ìƒìœ„ 80%)
        - ê´€ë ¨ì„±ì´ ë‚®ë”ë¼ë„ ì ì¬ì  ê°€ì¹˜ê°€ ìˆìœ¼ë©´ í¬í•¨
        - ë°°ê²½ ì •ë³´, ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        """
        # ìƒìœ„ 80% ì„¹ì…˜ ì„ íƒ
        sorted_sections = sorted(
            zip(sections, section_scores),
            key=lambda x: x[1].get('total_score', 0),
            reverse=True
        )
        top_count = max(3, int(len(sorted_sections) * 0.8))
        top_sections = [s for s, _ in sorted_sections[:top_count]]

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸´ ê¸¸ì´)
        context = "\n\n".join([
            f"[{title}]\n{content[:800]}..."
            for title, content in top_sections
        ])

        prompt = f"""ì§ˆë¬¸: {query}

ì»¨í…ìŠ¤íŠ¸ (ì „ì²´):
{context}

**í¬ê´„ì  ë‹µë³€ ê·œì¹™**:
1. ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ í¬í•¨
2. ë°°ê²½ ì§€ì‹, ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
3. ë‹¤ì–‘í•œ ê´€ì  ì œì‹œ
4. ìƒì„¸í•˜ê²Œ ë‹µë³€ (8-12ë¬¸ì¥)
5. ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì •ë³´ë„ í¬í•¨

ë‹µë³€:"""

        response = self.client.chat(model=self.model, messages=[
            {'role': 'user', 'content': prompt}
        ])

        answer_text = response['message']['content']
        used_sections = [title for title, _ in top_sections]

        return EnsembleAnswer(
            strategy=AnswerStrategy.COMPREHENSIVE,
            answer=answer_text,
            confidence=0.6,  # ë‚®ì€ ì‹ ë¢°ë„ (ì¶”ì¸¡ í¬í•¨)
            sources=used_sections
        )

    def synthesize_answers(self,
                          query: str,
                          ensemble_answers: List[EnsembleAnswer],
                          contradictions: List[str] = None) -> SynthesizedAnswer:
        """
        3ê°€ì§€ ë‹µë³€ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ìµœì¢… ì¢…í•© ë‹µë³€ ìƒì„±

        Args:
            query: ì›ë˜ ì§ˆë¬¸
            ensemble_answers: 3ê°€ì§€ ì „ëµì˜ ë‹µë³€ë“¤
            contradictions: ë°œê²¬ëœ ëª¨ìˆœ (ì˜µì…˜)

        Returns:
            SynthesizedAnswer: ì¢…í•©ëœ ìµœì¢… ë‹µë³€
        """
        # ê° ì „ëµë³„ ë‹µë³€ ì •ë¦¬
        strategy_breakdown = {}
        for ens_ans in ensemble_answers:
            strategy_name = ens_ans.strategy.value
            strategy_breakdown[strategy_name] = ens_ans.answer

        # ì¢…í•© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        answers_text = "\n\n".join([
            f"[{ens.strategy.value.upper()} - ì‹ ë¢°ë„ {ens.confidence:.0%}]\n{ens.answer}"
            for ens in ensemble_answers
        ])

        contradiction_text = ""
        if contradictions:
            contradiction_text = f"\n\nâš ï¸ ë°œê²¬ëœ ëª¨ìˆœ:\n" + "\n".join(contradictions)

        prompt = f"""ì§ˆë¬¸: {query}

ë‹¤ìŒì€ 3ê°€ì§€ ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ìƒì„±ëœ ë‹µë³€ë“¤ì…ë‹ˆë‹¤:

{answers_text}
{contradiction_text}

**ì¢…í•© ë‹µë³€ ìƒì„± ê·œì¹™**:
1. 3ê°€ì§€ ë‹µë³€ì„ ë¹„êµ ë¶„ì„
2. ê³µí†µëœ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œ
3. ìƒì¶©ë˜ëŠ” ë¶€ë¶„ì€ ì‹ ë¢°ë„ê°€ ë†’ì€ ìª½ ì„ íƒ
4. ëª¨ìˆœì´ ìˆìœ¼ë©´ ëª…ì‹œ
5. ìµœì¢… ì¢…í•© ë‹µë³€ ì‘ì„± (7-10ë¬¸ì¥)

ì¢…í•© ë‹µë³€:"""

        response = self.client.chat(model=self.model, messages=[
            {'role': 'user', 'content': prompt}
        ])

        final_answer = response['message']['content']

        # ì¢…í•© ê·¼ê±° ìƒì„±
        rationale_prompt = f"""ë‹¤ìŒ ì¢…í•© ë‹µë³€ì´ ë§Œë“¤ì–´ì§„ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”:

ì¢…í•© ë‹µë³€:
{final_answer}

ì›ë³¸ 3ê°€ì§€ ë‹µë³€:
{answers_text}

**ì„¤ëª… ê·œì¹™**:
1. ì–´ë–¤ ë¶€ë¶„ì´ ê³µí†µë˜ì–´ ì±„íƒë˜ì—ˆëŠ”ì§€
2. ì–´ë–¤ ë¶€ë¶„ì´ ì¶©ëŒí•˜ì—¬ ì¡°ì •ë˜ì—ˆëŠ”ì§€
3. ìµœì¢… ì„ íƒì˜ ê·¼ê±°
(3-5ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ)

ê·¼ê±°:"""

        rationale_response = self.client.chat(model=self.model, messages=[
            {'role': 'user', 'content': rationale_prompt}
        ])

        rationale = rationale_response['message']['content']

        # ì‹ ë¢°ë„ ê³„ì‚° (ì•™ìƒë¸” ë‹µë³€ë“¤ì˜ ê°€ì¤‘ í‰ê· )
        total_confidence = sum(ens.confidence for ens in ensemble_answers) / len(ensemble_answers)
        # ëª¨ìˆœì´ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ê°ì†Œ
        if contradictions:
            total_confidence *= (1 - len(contradictions) * 0.1)

        final_confidence = max(0, min(100, total_confidence * 100))

        # ëª¨ë“  ì„¹ì…˜ ìˆ˜ì§‘
        all_sections = []
        for ens in ensemble_answers:
            all_sections.extend(ens.sources)
        recommended_sections = list(set(all_sections))

        return SynthesizedAnswer(
            answer=final_answer,
            confidence=final_confidence,
            strategy_breakdown=strategy_breakdown,
            synthesis_rationale=rationale,
            recommended_sections=recommended_sections
        )


class AnswerFormatter:
    """ë‹µë³€ í¬ë§·í„°"""

    @staticmethod
    def format_ultra_response(synthesized: SynthesizedAnswer,
                              show_details: bool = False) -> str:
        """
        Ultra-Precision ë‹µë³€ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…

        Args:
            synthesized: ì¢…í•© ë‹µë³€
            show_details: ìƒì„¸ ì •ë³´ í‘œì‹œ ì—¬ë¶€

        Returns:
            str: í¬ë§·íŒ…ëœ ë‹µë³€
        """
        lines = []

        # 1. ìµœì¢… ë‹µë³€
        lines.append("=" * 60)
        lines.append("ğŸ“Œ Ultra-Precision ë‹µë³€")
        lines.append("=" * 60)
        lines.append("")
        lines.append(synthesized.answer)
        lines.append("")

        # 2. ì‹ ë¢°ë„
        confidence_bar = "â–ˆ" * int(synthesized.confidence / 5) + "â–‘" * (20 - int(synthesized.confidence / 5))
        lines.append(f"ğŸ¯ ì‹ ë¢°ë„: {synthesized.confidence:.1f}% [{confidence_bar}]")
        lines.append("")

        # 3. ì°¸ì¡° ì„¹ì…˜
        lines.append("ğŸ“š ì°¸ì¡° ì„¹ì…˜:")
        for i, section in enumerate(synthesized.recommended_sections, 1):
            lines.append(f"  {i}. {section}")
        lines.append("")

        # 4. ìƒì„¸ ì •ë³´ (ì˜µì…˜)
        if show_details:
            lines.append("-" * 60)
            lines.append("ğŸ” ì¢…í•© ë¶„ì„ ê³¼ì •")
            lines.append("-" * 60)
            lines.append("")

            # ì¢…í•© ê·¼ê±°
            lines.append("ğŸ“Š ì¢…í•© ê·¼ê±°:")
            lines.append(synthesized.synthesis_rationale)
            lines.append("")

            # ì „ëµë³„ ë‹µë³€
            lines.append("ğŸ“‹ ì „ëµë³„ ë‹µë³€:")
            for strategy, answer in synthesized.strategy_breakdown.items():
                lines.append(f"\n[{strategy.upper()}]")
                lines.append(answer[:300] + "..." if len(answer) > 300 else answer)
            lines.append("")

        lines.append("=" * 60)

        return "\n".join(lines)

    @staticmethod
    def format_reasoning_trace(trace: List[str]) -> str:
        """
        ì¶”ë¡  ê³¼ì • í¬ë§·íŒ…

        Args:
            trace: ì¶”ë¡  ê³¼ì • ë¡œê·¸

        Returns:
            str: í¬ë§·íŒ…ëœ ì¶”ë¡  ê³¼ì •
        """
        lines = []
        lines.append("\n" + "=" * 60)
        lines.append("ğŸ”¬ Ultra-Precision ì¶”ë¡  ê³¼ì •")
        lines.append("=" * 60)

        for i, step in enumerate(trace, 1):
            if step.startswith("Stage"):
                lines.append(f"\n{step}")
            else:
                lines.append(step)

        lines.append("=" * 60)

        return "\n".join(lines)
